{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4851fdd4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ef8168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error #add rmse\n",
    "from data import merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1896da",
   "metadata": {},
   "source": [
    "# Reading files and making it regressionable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9e51902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/merged/merged_cleaned_sentiment_train.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_val = pd.read_csv('data/merged/merged_cleaned_sentiment_validation.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_test = pd.read_csv('data/merged/merged_cleaned_sentiment_test.csv').drop(['pos','neg','neu', 'compound'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a0c5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['danceability', 'energy', 'instrumentalness', 'valence','mode', 'y_valence', 'y_arousal']]\n",
    "df_val = df_val[['danceability', 'energy', 'instrumentalness', 'valence','mode', 'y_valence', 'y_arousal']]\n",
    "df_test = df_test[['danceability', 'energy', 'instrumentalness', 'valence','mode','y_valence', 'y_arousal']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf147c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, pd.read_csv('data/lyrics/lyrics_features_train.csv').iloc[:, :-200]], axis=1)\n",
    "df_val = pd.concat([df_val, pd.read_csv('data/lyrics/lyrics_features_val.csv').iloc[:, :-200]], axis=1)\n",
    "df_test = pd.concat([df_test, pd.read_csv('data/lyrics/lyrics_features_test.csv').iloc[:, :-200]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943db10",
   "metadata": {},
   "source": [
    "### This was when we used all audio features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a358f",
   "metadata": {},
   "source": [
    "df_train = pd.concat([df_train, pd.get_dummies(df_train.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_val = pd.concat([df_val, pd.get_dummies(df_val.key, drop_first = True, prefix = 'key')], axis=1)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_val.key, drop_first = True, prefix = 'key')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512cfc24",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_train = df_train.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key','lyrics_cleaned' ], axis=1)\n",
    "df_val = df_val.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key', 'lyrics_cleaned' ], axis=1)\n",
    "df_test = df_test.drop(['Unnamed: 0', 'artist', 'trackname', 'id', 'time_signature', 'lyrics', 'key', 'lyrics_cleaned'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f979108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_val = df_val.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f0a887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'instrumentalness', 'valence', 'mode',\n",
       "       'y_valence', 'y_arousal', 'Unnamed: 0', 'pos', 'neg',\n",
       "       ...\n",
       "       'tfidf_pca_91', 'tfidf_pca_92', 'tfidf_pca_93', 'tfidf_pca_94',\n",
       "       'tfidf_pca_95', 'tfidf_pca_96', 'tfidf_pca_97', 'tfidf_pca_98',\n",
       "       'tfidf_pca_99', 'tfidf_pca_100'],\n",
       "      dtype='object', length=112)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd5f2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get cross validation scores\n",
    "def get_cv_scores(model, X_train, y_train):\n",
    "    scores = cross_val_score(model,\n",
    "                             X_train,\n",
    "                             y_train,\n",
    "                             cv=5,\n",
    "                             scoring='r2')\n",
    "    \n",
    "    print('CV Mean: ', np.mean(scores))\n",
    "    print('STD: ', np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275770ba",
   "metadata": {},
   "source": [
    "# Splitting the data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc2128c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     train set\n",
    "X_train = df_train.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_train_valence = df_train.y_valence.values \n",
    "y_train_arousal = df_train.y_arousal.values\n",
    "    \n",
    "#     validation set\n",
    "X_val = df_val.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_val_valence = df_val.y_valence.values \n",
    "y_val_arousal = df_val.y_arousal.values \n",
    "\n",
    "#      test set\n",
    "X_test = df_test.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "y_test_valence = df_test.y_valence.values \n",
    "y_test_arousal = df_test.y_arousal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a18e096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054508397801767416"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().fit(y_train_arousal.reshape(-1, 1), y_train_valence.reshape(-1, 1)).score(y_train_arousal.reshape(-1, 1), y_train_valence.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a867712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "    \n",
    "\n",
    "    # parameters\n",
    "    param_grid = {'fit_intercept':[True,False], 'positive':[True, False]}\n",
    "    \n",
    "    # Initialize model for Grid search\n",
    "    lr_val = LinearRegression()\n",
    "    lr_arou = LinearRegression()\n",
    "    \n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(lr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(lr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    lr_val_top = LinearRegression(fit_intercept=clf_vale.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_vale.best_params_['positive'])\n",
    "    lr_arou_top = LinearRegression(fit_intercept=clf_arou.best_params_['fit_intercept'],  \n",
    "                                    positive = clf_arou.best_params_['positive'])\n",
    "\n",
    "    # get cross val scores for models \n",
    "    get_cv_scores(lr_val_top, X, y_1)\n",
    "    get_cv_scores(lr_arou_top, X, y_2)\n",
    "\n",
    "\n",
    "    #fit optimal models to train data \n",
    "    lr_val_fit = lr_val_top.fit(X, y_1)\n",
    "    lr_arou_fit = lr_arou_top.fit(X, y_2)\n",
    "    \n",
    "    # validation scores \n",
    "    r2_validation_valence = lr_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = lr_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e211ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forest_regression(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "    \n",
    "    # Initialize models\n",
    "    rf_val = RandomForestRegressor(random_state=0)\n",
    "    rf_arou = RandomForestRegressor(random_state=0)\n",
    "    \n",
    "    param_grid = { \n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth' : [5,10, 15]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(rf_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(rf_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "\n",
    "    # Print best results on training data\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "\n",
    "\n",
    "    #Initialize models with best parameters\n",
    "    rf_val_top = RandomForestRegressor(n_estimators = clf_vale.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_vale.best_params_['max_depth'], random_state=0)\n",
    "    rf_arou_top = RandomForestRegressor(n_estimators = clf_arou.best_params_['n_estimators'], \n",
    "                                        max_depth = clf_arou.best_params_['max_depth'], random_state=0)\n",
    "    \n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(rf_val_top, X, y_1)\n",
    "    get_cv_scores(rf_arou_top, X, y_2)\n",
    "\n",
    "    rf_val_fit = rf_val_top.fit(X, y_1)\n",
    "    rf_arou_fit = rf_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = rf_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = rf_arou_fit.score(X_validation, y_2_validation)\n",
    "\n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "    \n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57838728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svr(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "\n",
    "    # Train model\n",
    "    svr_val = SVR()\n",
    "    svr_arou = SVR()\n",
    "    \n",
    "    param_grid = {'kernel' : ('linear', 'rbf', 'poly'),\n",
    "                  'C' : [1,5,10]\n",
    "                 }\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(svr_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(svr_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    svr_val_top = SVR(kernel = clf_vale.best_params_['kernel'], C = clf_vale.best_params_['C'])\n",
    "    svr_arou_top = SVR(kernel = clf_arou.best_params_['kernel'], C = clf_arou.best_params_['C'])\n",
    "\n",
    "\n",
    "    # get cross val scores\n",
    "    get_cv_scores(svr_val_top, X, y_1)\n",
    "    get_cv_scores(svr_arou_top, X, y_2)\n",
    "\n",
    "    #fit\n",
    "    svr_val_fit = svr_val_top.fit(X,y_1)\n",
    "    svr_arou_fit = svr_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = svr_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = svr_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "\n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "467c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mlp(X, y_1, y_2, X_validation, y_1_validation, y_2_validation):\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_validation = scaler.fit_transform(X_validation)\n",
    "\n",
    "    # Initialize model\n",
    "    mlp_val = MLPRegressor(random_state = 2)\n",
    "    mlp_arou = MLPRegressor(random_state = 2)\n",
    "    \n",
    "    param_grid = {'hidden_layer_sizes':[(5), (10), (15), (5,5), (10,10), (15,15), (5,5,5), (10,10,10), (15,15,15)], \n",
    "    'max_iter':[500, 1000, 2000, 2500]}\n",
    "\n",
    "    # Grid search\n",
    "    clf_vale = GridSearchCV(mlp_val, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "    \n",
    "    clf_arou = GridSearchCV(mlp_arou, \n",
    "                            param_grid, \n",
    "                            scoring='r2', \n",
    "                            verbose=1, \n",
    "                            n_jobs=-1,\n",
    "                            return_train_score=True)\n",
    "\n",
    "\n",
    "    # Print best results on training data    \n",
    "    clf_vale.fit(X, y_1)\n",
    "    clf_arou.fit(X, y_2)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(\"Best parameter for Valence (CV score=%0.3f):\" % clf_vale.best_score_)\n",
    "    print(clf_vale.best_params_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Best parameter for Arousal (CV score=%0.3f):\" % clf_arou.best_score_)\n",
    "    print(clf_arou.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    #Train model with best params\n",
    "    mlp_val_top = MLPRegressor(hidden_layer_sizes=clf_vale.best_params_['hidden_layer_sizes'], max_iter=clf_vale.best_params_['max_iter'], random_state = 2)\n",
    "    mlp_arou_top = MLPRegressor(hidden_layer_sizes=clf_arou.best_params_['hidden_layer_sizes'], max_iter=clf_arou.best_params_['max_iter'], random_state = 2)\n",
    "\n",
    "    # get cross val scores \n",
    "    get_cv_scores(mlp_val_top, X, y_1)\n",
    "    get_cv_scores(mlp_arou_top, X, y_2)\n",
    "\n",
    "    mlp_val_fit = mlp_val_top.fit(X, y_1)\n",
    "    mlp_arou_fit = mlp_arou_top.fit(X, y_2)\n",
    "    \n",
    "    r2_validation_valence = mlp_val_fit.score(X_validation, y_1_validation)\n",
    "    r2_validation_arousal = mlp_arou_fit.score(X_validation, y_2_validation)\n",
    "    \n",
    "    print()\n",
    "    print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "    print(f'Validation score for Arousal: {r2_validation_arousal}')\n",
    "\n",
    "    \n",
    "    return clf_vale.best_params_, clf_arou.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b5677",
   "metadata": {},
   "source": [
    "### Random Forest Regression - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14a6a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_par_rf, arou_par_rf \u001b[38;5;241m=\u001b[39m \u001b[43mdo_forest_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_arousal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_valence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_arousal\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[54], line 28\u001b[0m, in \u001b[0;36mdo_forest_regression\u001b[0;34m(X, y_1, y_2, X_validation, y_1_validation, y_2_validation)\u001b[0m\n\u001b[1;32m     20\u001b[0m clf_arou \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_arou, \n\u001b[1;32m     21\u001b[0m                         param_grid, \n\u001b[1;32m     22\u001b[0m                         scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     23\u001b[0m                         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     24\u001b[0m                         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     25\u001b[0m                         return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print best results on training data    \u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mclf_vale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m clf_arou\u001b[38;5;241m.\u001b[39mfit(X, y_2)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Print best results on training data\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_par_rf, arou_par_rf = do_forest_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0b706",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "    Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.185):\n",
    "    {'max_depth': 10, 'n_estimators': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.199):\n",
    "    {'max_depth': 10, 'n_estimators': 500}\n",
    "    CV Mean:  0.18477634266575188\n",
    "    STD:  0.010064224970315037\n",
    "    CV Mean:  0.1987682194468258\n",
    "    STD:  0.025811738331714372\n",
    "\n",
    "    Validation score for Valence: 0.17296757628631831\n",
    "    Validation score for Arousal: 0.24101399592965878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bda13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcae7dd7",
   "metadata": {},
   "source": [
    "#### Test Set - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_val = RandomForestRegressor(n_estimators = 100, \n",
    "                                        max_depth = 5, random_state=0)\n",
    "rf_arou = RandomForestRegressor(n_estimators = 100, \n",
    "                                        max_depth = 5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e56a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21563447935080082\n",
      "0.2031321009223268\n"
     ]
    }
   ],
   "source": [
    "print(rf_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(rf_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d477cd",
   "metadata": {},
   "source": [
    "### Linear Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb39853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.192):\n",
      "{'fit_intercept': True, 'positive': False}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.165):\n",
      "{'fit_intercept': False, 'positive': False}\n",
      "\n",
      "CV Mean:  0.19156200216250585\n",
      "STD:  0.012919083070775876\n",
      "CV Mean:  0.1646334689838204\n",
      "STD:  0.02101493280205238\n",
      "\n",
      "Validation score for Valence: 0.18598784431685378\n",
      "Validation score for Arousal: 0.19393910784235824\n"
     ]
    }
   ],
   "source": [
    "val_par, arou_par = do_regression(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379e45b",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "    Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.193):\n",
    "    {'fit_intercept': True, 'positive': False}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.164):\n",
    "    {'fit_intercept': True, 'positive': True}\n",
    "\n",
    "    CV Mean:  0.19263909417367236\n",
    "    STD:  0.01423911801666168\n",
    "    CV Mean:  0.16387005569169152\n",
    "    STD:  0.013789304326383702\n",
    "\n",
    "    Validation score for Valence: 0.18365452891704448\n",
    "    Validation score for Arousal: 0.18418929034767606"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c397f",
   "metadata": {},
   "source": [
    "#### LR Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_val = LinearRegression(fit_intercept=val_par['fit_intercept'],  \n",
    "                                    positive = val_par['positive'])\n",
    "lr_arou = LinearRegression(fit_intercept=arou_par['fit_intercept'],  \n",
    "                                    positive = arou_par['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c9780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23522504334112415\n",
      "0.18979073068866747\n"
     ]
    }
   ],
   "source": [
    "print(lr_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(lr_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be573fb",
   "metadata": {},
   "source": [
    "### Support Vector Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.171):\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.157):\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "CV Mean:  0.17060915752620148\n",
      "STD:  0.016451994401807103\n",
      "CV Mean:  0.15681334193429142\n",
      "STD:  0.021609634567641076\n",
      "\n",
      "Validation score for Valence: 0.14513143825250574\n",
      "Validation score for Arousal: 0.17697077330583544\n"
     ]
    }
   ],
   "source": [
    "val_par_svr, arou_par_svr = do_svr(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e747b46",
   "metadata": {},
   "source": [
    "#### Test Score - SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_val = SVR(kernel = val_par_svr['kernel'], C = val_par_svr['C'])\n",
    "svr_arou = SVR(kernel = arou_par_svr['kernel'], C = arou_par_svr['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c389c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21211076671348172\n",
      "0.17257770158185026\n"
     ]
    }
   ],
   "source": [
    "print(svr_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(svr_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360deed0",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Regression - optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.200):\n",
      "{'hidden_layer_sizes': (5, 5), 'max_iter': 500}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.175):\n",
      "{'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
      "\n",
      "CV Mean:  0.19950950041566404\n",
      "STD:  0.015591862192069152\n",
      "CV Mean:  0.17458027826593903\n",
      "STD:  0.021119598144282097\n",
      "\n",
      "Validation score for Valence: 0.18311694698515346\n",
      "Validation score for Arousal: 0.2009258008111775\n"
     ]
    }
   ],
   "source": [
    "val_par_mlp, arou_par_mlp = do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18724bea",
   "metadata": {},
   "source": [
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "    Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
    "\n",
    "    Best parameter for Valence (CV score=0.198):\n",
    "    {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
    "\n",
    "    Best parameter for Arousal (CV score=0.177):\n",
    "    {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
    "\n",
    "    CV Mean:  0.19816558523065714\n",
    "    STD:  0.013616324243766003\n",
    "    CV Mean:  0.17746596775912477\n",
    "    STD:  0.022757705925352777\n",
    "\n",
    "    Validation score for Valence: 0.16755552530343532\n",
    "    Validation score for Arousal: 0.2115436506271312\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f83a62",
   "metadata": {},
   "source": [
    "### Test Set - MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32971f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_val = MLPRegressor(hidden_layer_sizes=val_par_mlp['hidden_layer_sizes'], max_iter=val_par_mlp['max_iter'], random_state = 2)\n",
    "mlp_arou = MLPRegressor(hidden_layer_sizes=arou_par_mlp['hidden_layer_sizes'], max_iter=arou_par_mlp['max_iter'], random_state = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65496288",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c597109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7596, 110)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2380058059037995\n",
      "0.19579112679579103\n"
     ]
    }
   ],
   "source": [
    "print(mlp_val.fit(X_train, y_train_valence).score(X_test, y_test_valence))\n",
    "print(mlp_arou.fit(X_train, y_train_arousal).score(X_test, y_test_arousal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b93966",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66892e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44659e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 FEATURES\n",
      "CV Mean:  0.16450630521856338\n",
      "STD:  0.013886221462250624\n",
      "CV Mean:  0.16240066093528122\n",
      "STD:  0.016278244786631514\n",
      "\n",
      "10 FEATURES\n",
      "CV Mean:  0.17711296964776696\n",
      "STD:  0.012236324459514152\n",
      "CV Mean:  0.16629974906378792\n",
      "STD:  0.013766632635808412\n",
      "\n",
      "15 FEATURES\n",
      "CV Mean:  0.1858072293248198\n",
      "STD:  0.012142036198196548\n",
      "CV Mean:  0.16707987220261172\n",
      "STD:  0.012195808791533468\n",
      "\n",
      "20 FEATURES\n",
      "CV Mean:  0.18750891541565198\n",
      "STD:  0.012395120883625089\n",
      "CV Mean:  0.1710413548962561\n",
      "STD:  0.012456230700412279\n",
      "\n",
      "25 FEATURES\n",
      "CV Mean:  0.18757014047620452\n",
      "STD:  0.011272469226122862\n",
      "CV Mean:  0.1706936926551956\n",
      "STD:  0.012209891108903371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [5,10,15,20,25]:\n",
    "\n",
    "    print(i, 'FEATURES')\n",
    "    estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector = RFE(estimator, n_features_to_select=i, step=1)\n",
    "    selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "    estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "    selector2 = RFE(estimator2, n_features_to_select=i, step=1)\n",
    "    selector_arou = selector2.fit(X_train, y_train_arousal)\n",
    "\n",
    "    lr_valence = LinearRegression(fit_intercept= True, positive= True)\n",
    "    lr_arousal = LinearRegression(fit_intercept= True, positive= True)\n",
    "    get_cv_scores(estimator, X_train[:,selector.support_], y_train_valence)\n",
    "    get_cv_scores(estimator, X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 features\n",
    "estimator = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector = RFE(estimator, n_features_to_select=20, step=1)\n",
    "selector = selector.fit(X_train, y_train_valence)\n",
    "\n",
    "estimator2 = LinearRegression(fit_intercept= True, positive= True)\n",
    "selector2 = RFE(estimator2, n_features_to_select=20, step=1)\n",
    "selector_arou = selector2.fit(X_train, y_train_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbf3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_valence = MLPRegressor(hidden_layer_sizes= (10,10), max_iter=500)\n",
    "mlp_arousal = MLPRegressor(hidden_layer_sizes= 5, max_iter=500)\n",
    "mlp_val_fit = mlp_valence.fit(X_train[:,selector.support_], y_train_valence)\n",
    "mlp_arou_fit = mlp_arousal.fit(X_train[:,selector_arou.support_], y_train_arousal)\n",
    "\n",
    "r2_validation_valence = mlp_val_fit.score(X_val[:,selector.support_], y_val_valence)\n",
    "r2_validation_arousal = mlp_arou_fit.score(X_val[:,selector_arou.support_], y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation score for Valence: -0.10761250799503541\n",
      "Validation score for Arousal: -0.22313442641479098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "print(f'Validation score for Valence: {r2_validation_valence}')\n",
    "print(f'Validation score for Arousal: {r2_validation_arousal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ec7a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 112 but corresponding boolean dimension is 110",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:4616\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   4614\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 4616\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(result):\n\u001b[1;32m   4618\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"ndim\" has incompatible type \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   4619\u001b[0m     \u001b[38;5;66;03m# Any]\"; expected \"Union[Union[int, float, complex, str, bytes, generic],\u001b[39;00m\n\u001b[1;32m   4620\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], _SupportsArray]\"\u001b[39;00m\n\u001b[1;32m   4622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 112 but corresponding boolean dimension is 110"
     ]
    }
   ],
   "source": [
    "df_train.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb71b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 112 but corresponding boolean dimension is 110",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselector2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:4616\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   4614\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 4616\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(result):\n\u001b[1;32m   4618\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"ndim\" has incompatible type \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   4619\u001b[0m     \u001b[38;5;66;03m# Any]\"; expected \"Union[Union[int, float, complex, str, bytes, generic],\u001b[39;00m\n\u001b[1;32m   4620\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], _SupportsArray]\"\u001b[39;00m\n\u001b[1;32m   4622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 112 but corresponding boolean dimension is 110"
     ]
    }
   ],
   "source": [
    "df_train.columns[selector2.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bec6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "      <th>y_valence</th>\n",
       "      <th>y_arousal</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_pca_91</th>\n",
       "      <th>tfidf_pca_92</th>\n",
       "      <th>tfidf_pca_93</th>\n",
       "      <th>tfidf_pca_94</th>\n",
       "      <th>tfidf_pca_95</th>\n",
       "      <th>tfidf_pca_96</th>\n",
       "      <th>tfidf_pca_97</th>\n",
       "      <th>tfidf_pca_98</th>\n",
       "      <th>tfidf_pca_99</th>\n",
       "      <th>tfidf_pca_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.25100</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.682725</td>\n",
       "      <td>0.316758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>-0.032266</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>-0.035761</td>\n",
       "      <td>-0.011026</td>\n",
       "      <td>-0.018885</td>\n",
       "      <td>0.017530</td>\n",
       "      <td>-0.040245</td>\n",
       "      <td>0.018009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.434</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.45100</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>-0.923151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007425</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>-0.057914</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.023851</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>-0.012319</td>\n",
       "      <td>-0.035166</td>\n",
       "      <td>-0.003449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0</td>\n",
       "      <td>1.071901</td>\n",
       "      <td>0.846830</td>\n",
       "      <td>2</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>-0.019298</td>\n",
       "      <td>-0.058143</td>\n",
       "      <td>0.030132</td>\n",
       "      <td>-0.020258</td>\n",
       "      <td>-0.017809</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>-0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.056572</td>\n",
       "      <td>0.736206</td>\n",
       "      <td>3</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>-0.003824</td>\n",
       "      <td>0.027660</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>-0.006385</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.00816</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1</td>\n",
       "      <td>1.541257</td>\n",
       "      <td>1.704165</td>\n",
       "      <td>4</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>-0.020362</td>\n",
       "      <td>-0.016839</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-0.018892</td>\n",
       "      <td>0.018980</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>-0.001808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  instrumentalness  valence  mode  y_valence  \\\n",
       "0         0.320   0.798           0.25100    0.407     0  -0.682725   \n",
       "1         0.434   0.600           0.45100    0.753     0   0.373325   \n",
       "2         0.530   0.270           0.00000    0.515     0   1.071901   \n",
       "3         0.479   0.528           0.00128    0.185     0  -1.056572   \n",
       "4         0.639   0.893           0.00816    0.966     1   1.541257   \n",
       "\n",
       "   y_arousal  Unnamed: 0    pos    neg  ...  tfidf_pca_91  tfidf_pca_92  \\\n",
       "0   0.316758           0  0.142  0.174  ...      0.015783     -0.032266   \n",
       "1  -0.923151           1  0.276  0.000  ...      0.007425      0.006276   \n",
       "2   0.846830           2  0.159  0.095  ...      0.018198     -0.019298   \n",
       "3   0.736206           3  0.099  0.037  ...      0.007089      0.009937   \n",
       "4   1.704165           4  0.231  0.106  ...      0.003749      0.004186   \n",
       "\n",
       "   tfidf_pca_93  tfidf_pca_94  tfidf_pca_95  tfidf_pca_96  tfidf_pca_97  \\\n",
       "0      0.006463     -0.003021     -0.035761     -0.011026     -0.018885   \n",
       "1     -0.057914      0.006029      0.000979     -0.023851     -0.010867   \n",
       "2     -0.058143      0.030132     -0.020258     -0.017809      0.049364   \n",
       "3     -0.003824      0.027660     -0.017931      0.004531     -0.013273   \n",
       "4     -0.020362     -0.016839      0.005286     -0.018892      0.018980   \n",
       "\n",
       "   tfidf_pca_98  tfidf_pca_99  tfidf_pca_100  \n",
       "0      0.017530     -0.040245       0.018009  \n",
       "1     -0.012319     -0.035166      -0.003449  \n",
       "2     -0.004692      0.012285      -0.009272  \n",
       "3     -0.006385     -0.000347       0.001329  \n",
       "4      0.016430      0.000353      -0.001808  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea06f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Best parameter for Valence (CV score=0.200):\n",
      "{'hidden_layer_sizes': (5, 5), 'max_iter': 500}\n",
      "\n",
      "Best parameter for Arousal (CV score=0.175):\n",
      "{'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500}\n",
      "\n",
      "CV Mean:  0.19950950041566404\n",
      "STD:  0.015591862192069152\n",
      "CV Mean:  0.17458027826593903\n",
      "STD:  0.021119598144282097\n",
      "\n",
      "Validation score for Valence: 0.18311694698515346\n",
      "Validation score for Arousal: 0.2009258008111775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'hidden_layer_sizes': (5, 5), 'max_iter': 500},\n",
       " {'hidden_layer_sizes': (5, 5, 5), 'max_iter': 500})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_mlp(X_train, y_train_valence, y_train_arousal, X_val, y_val_valence, y_val_arousal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5a620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
